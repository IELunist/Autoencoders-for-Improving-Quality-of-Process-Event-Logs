{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note:**\n",
    "- nan_index_matrix: 1: missing index, 0: available index --> test function\n",
    "- avai_index_matrix: 1: available index, 0: missing index --> cost evaluation\n",
    "- **avai_index_matrix != 1 - nan_test** because of 0 padding\n",
    "- For training: Use avai_train and avai_val\n",
    "- For predicting: Use avai_test\n",
    "- For testing: Use nan_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import argparse\n",
    "import os, sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, './../utils/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define parser\n",
    "#name = 'bpi_2012'\n",
    "name = 'bpi_2013'\n",
    "#name = 'helpdesk'  \n",
    "\n",
    "parser = {\n",
    "    'data_dir': '../data/',\n",
    "    'data_file': name + '.csv',\n",
    "    'input_dir': '../input/{}/'.format(name),  \n",
    "    'batch_size' : 16,\n",
    "    'epochs' : 200,\n",
    "    'no_cuda' : True,\n",
    "    'seed' : 7,\n",
    "    'log_interval' : 1000,\n",
    "    'z_dim': 10,\n",
    "    'h_dim': 200,\n",
    "    'output_size': 10,\n",
    "    'lr': 0.001,\n",
    "    'betas': (0.9, 0.999),   \n",
    "    'lr_decay': 0.95,\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(args.input_dir + 'preprocessed_data.pkl', 'rb') as f:\n",
    "    #nan_index_matrix = pickle.load(f)\n",
    "    #f_dim_list = pickle.load(f)\n",
    "    #s_dim_list = pickle.load(f)\n",
    "    #t_dim_list = pickle.load(f)\n",
    "    min_array = pickle.load(f)\n",
    "    max_array = pickle.load(f)\n",
    "    c_train = pickle.load(f) #normalized\n",
    "    avai_train = pickle.load(f) #index vector\n",
    "    true_train = pickle.load(f) #true values\n",
    "    c_val = pickle.load(f)\n",
    "    avai_val = pickle.load(f)\n",
    "    nan_val = pickle.load(f)\n",
    "    true_val = pickle.load(f)\n",
    "    c_test = pickle.load(f)\n",
    "    avai_test = pickle.load(f)\n",
    "    nan_test = pickle.load(f)\n",
    "    true_test = pickle.load(f)\n",
    "    m_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1040, 35, 8), (299, 35, 8), (1040, 35, 8))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train.shape, c_test.shape, avai_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(c_train, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
    "avai_train_loader = torch.utils.data.DataLoader(avai_train, batch_size=args.batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(args.z_dim, args.h_dim) \n",
    "        self.fc2 = nn.Linear(args.h_dim, args.h_dim)\n",
    "        self.fc3 = nn.Linear(args.h_dim, args.output_size)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(c_train.shape[1]*c_train.shape[2], args.h_dim)\n",
    "        self.fc2 = nn.Linear(args.h_dim, args.h_dim)\n",
    "        self.fc3 = nn.Linear(args.h_dim, args.output_size)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.fc1(x))\n",
    "        x = self.elu(self.fc2(x))\n",
    "        return self.sigmoid(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "\n",
    "if args.cuda:\n",
    "    D.cuda()\n",
    "    G.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define loss\n",
    "recon_function = nn.BCELoss()\n",
    "recon_function.size_average = False #loss sum of each mini-batch\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    #x = recon_x*index_nan_matrix\n",
    "    BCE = recon_function(recon_x, x)  \n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D_optimizer = optim.Adam(D.parameters(), lr=args.lr, betas=args.betas)\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=args.lr, betas=args.betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Adjust learning rate per epoch: http://pytorch.org/docs/master/optim.html?highlight=adam#torch.optim.Adam\n",
    "lambda1 = lambda epoch: args.lr_decay ** epoch\n",
    "D_scheduler = torch.optim.lr_scheduler.LambdaLR(D_optimizer, lr_lambda=[lambda1])\n",
    "G_scheduler = torch.optim.lr_scheduler.LambdaLR(G_optimizer, lr_lambda=[lambda1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (c_data, avai_index) in enumerate(zip(train_loader, avai_train_loader)):\n",
    "        m_data = c_data*avai_index\n",
    "        \n",
    "        c_data = Variable(c_data.float())\n",
    "        m_data = Variable(m_data.float())\n",
    "        #Transform: np --> Tensor/Variable: tensor --> tensor with wrapper\n",
    "        #Wraps a tensor and records the operations applied to it.\n",
    "        #Variable is a thin wrapper around a Tensor object, that also holds the gradient\n",
    "        if args.cuda:\n",
    "            c_data = c_data.cuda()\n",
    "            m_data = m_data.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_data, mu, logvar = model(m_data)\n",
    "        \n",
    "        loss = loss_function(recon_data, c_data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track performance of each batch\n",
    "        #if batch_idx % args.log_interval == 0:\n",
    "        #    print('Train Epoch {}: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch, batch_idx * len(m_data), len(train_loader.dataset),\n",
    "        #        100. * batch_idx / len(train_loader),\n",
    "        #        loss.data[0] / len(m_data)))\n",
    "    \n",
    "    # Track performance of each epoch\n",
    "    print('====> Epoch {}: Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # Sample data\n",
    "    #X.size(0) = batch_size\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for X, _ in train_loader:\n",
    "        # Create ones_label and zeros_label\n",
    "        ones_label = Variable(torch.ones(X.size(0)))\n",
    "        zeros_label = Variable(torch.zeros(X.size(0)))\n",
    "        \n",
    "        # Input: z - latent variables, x - input\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        X = Variable(X.view(-1, 784))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z) # X_fake: generate from Generator\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        # Calculate loss\n",
    "        D_loss_real = F.binary_cross_entropy(D_real, ones_label) # compare D_real with 1\n",
    "        D_loss_fake = F.binary_cross_entropy(D_fake, zeros_label) # compare D_fake with 0\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "        \n",
    "        # Tinh dao ham cua D_loss vs cac Variable require_grad = true\n",
    "        D_loss.backward()\n",
    "        \n",
    "        # update params\n",
    "        D_solver.step()\n",
    "\n",
    "        #---------------------------------------------------#\n",
    "        \n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        G_sample = G(z)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        G_loss = F.binary_cross_entropy(D_fake, ones_label) # Compare D_fake with 1\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "        \n",
    "        # Back-ward\n",
    "        G_loss.backward()\n",
    "        \n",
    "        # Update\n",
    "        G_solver.step()\n",
    "        \n",
    "        #D_losses.add(D_loss.data[0], X.size(0))\n",
    "        #G_losses.add(G_loss.data[0], X.size(0))\n",
    "        \n",
    "        # Test A. Du's loss\n",
    "        D_losses.add(D_loss.data[0]*X.size(0), X.size(0))\n",
    "        G_losses.add(G_loss.data[0]*X.size(0), X.size(0))\n",
    "\n",
    "    print('Epoch-{}; D_loss: {}; G_loss: {}'.format(epoch, D_losses.value()[0], G_losses.value()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([16, 35, 8])) that is different to the input size (torch.Size([16, 280])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch 1: Average loss: 71.9227\n",
      "====> Epoch 2: Average loss: 17.9910\n",
      "====> Epoch 3: Average loss: 14.5593\n",
      "====> Epoch 4: Average loss: 13.3151\n",
      "====> Epoch 5: Average loss: 12.7568\n",
      "====> Epoch 6: Average loss: 12.1360\n",
      "====> Epoch 7: Average loss: 11.6116\n",
      "====> Epoch 8: Average loss: 11.2126\n",
      "====> Epoch 9: Average loss: 10.7439\n",
      "====> Epoch 10: Average loss: 10.4606\n",
      "====> Epoch 11: Average loss: 10.2406\n",
      "====> Epoch 12: Average loss: 10.0669\n",
      "====> Epoch 13: Average loss: 9.7552\n",
      "====> Epoch 14: Average loss: 9.6034\n",
      "====> Epoch 15: Average loss: 9.3990\n",
      "====> Epoch 16: Average loss: 9.4100\n",
      "====> Epoch 17: Average loss: 9.0981\n",
      "====> Epoch 18: Average loss: 9.2005\n",
      "====> Epoch 19: Average loss: 9.2505\n",
      "====> Epoch 20: Average loss: 9.0390\n",
      "====> Epoch 21: Average loss: 9.0877\n",
      "====> Epoch 22: Average loss: 9.0691\n",
      "====> Epoch 23: Average loss: 9.0350\n",
      "====> Epoch 24: Average loss: 8.9399\n",
      "====> Epoch 25: Average loss: 8.9722\n",
      "====> Epoch 26: Average loss: 8.8671\n",
      "====> Epoch 27: Average loss: 8.7930\n",
      "====> Epoch 28: Average loss: 8.7844\n",
      "====> Epoch 29: Average loss: 8.7960\n",
      "====> Epoch 30: Average loss: 8.8024\n",
      "====> Epoch 31: Average loss: 8.7823\n",
      "====> Epoch 32: Average loss: 8.6595\n",
      "====> Epoch 33: Average loss: 8.6608\n",
      "====> Epoch 34: Average loss: 8.6318\n",
      "====> Epoch 35: Average loss: 8.5291\n",
      "====> Epoch 36: Average loss: 8.5416\n",
      "====> Epoch 37: Average loss: 8.5272\n",
      "====> Epoch 38: Average loss: 8.3534\n",
      "====> Epoch 39: Average loss: 8.4005\n",
      "====> Epoch 40: Average loss: 8.5029\n",
      "====> Epoch 41: Average loss: 8.3682\n",
      "====> Epoch 42: Average loss: 8.4900\n",
      "====> Epoch 43: Average loss: 8.3869\n",
      "====> Epoch 44: Average loss: 8.3143\n",
      "====> Epoch 45: Average loss: 8.3352\n",
      "====> Epoch 46: Average loss: 8.3263\n",
      "====> Epoch 47: Average loss: 8.3284\n",
      "====> Epoch 48: Average loss: 8.2561\n",
      "====> Epoch 49: Average loss: 8.1925\n",
      "====> Epoch 50: Average loss: 8.2369\n",
      "====> Epoch 51: Average loss: 8.1417\n",
      "====> Epoch 52: Average loss: 8.3106\n",
      "====> Epoch 53: Average loss: 8.1705\n",
      "====> Epoch 54: Average loss: 8.0775\n",
      "====> Epoch 55: Average loss: 8.1330\n",
      "====> Epoch 56: Average loss: 8.0841\n",
      "====> Epoch 57: Average loss: 7.9614\n",
      "====> Epoch 58: Average loss: 7.9820\n",
      "====> Epoch 59: Average loss: 7.9936\n",
      "====> Epoch 60: Average loss: 7.9696\n",
      "====> Epoch 61: Average loss: 8.0426\n",
      "====> Epoch 62: Average loss: 8.1384\n",
      "====> Epoch 63: Average loss: 8.0217\n",
      "====> Epoch 64: Average loss: 7.9095\n",
      "====> Epoch 65: Average loss: 7.9567\n",
      "====> Epoch 66: Average loss: 7.9305\n",
      "====> Epoch 67: Average loss: 7.9284\n",
      "====> Epoch 68: Average loss: 7.7880\n",
      "====> Epoch 69: Average loss: 7.8473\n",
      "====> Epoch 70: Average loss: 7.8542\n",
      "====> Epoch 71: Average loss: 7.8876\n",
      "====> Epoch 72: Average loss: 7.7666\n",
      "====> Epoch 73: Average loss: 7.7385\n",
      "====> Epoch 74: Average loss: 7.8502\n",
      "====> Epoch 75: Average loss: 7.7393\n",
      "====> Epoch 76: Average loss: 7.8298\n",
      "====> Epoch 77: Average loss: 7.7889\n",
      "====> Epoch 78: Average loss: 7.7028\n",
      "====> Epoch 79: Average loss: 7.8147\n",
      "====> Epoch 80: Average loss: 7.6902\n",
      "====> Epoch 81: Average loss: 7.7108\n",
      "====> Epoch 82: Average loss: 7.6654\n",
      "====> Epoch 83: Average loss: 7.6271\n",
      "====> Epoch 84: Average loss: 7.6748\n",
      "====> Epoch 85: Average loss: 7.6504\n",
      "====> Epoch 86: Average loss: 7.6631\n",
      "====> Epoch 87: Average loss: 7.6369\n",
      "====> Epoch 88: Average loss: 7.7028\n",
      "====> Epoch 89: Average loss: 7.6645\n",
      "====> Epoch 90: Average loss: 7.5983\n",
      "====> Epoch 91: Average loss: 7.6529\n",
      "====> Epoch 92: Average loss: 7.5172\n",
      "====> Epoch 93: Average loss: 7.5755\n",
      "====> Epoch 94: Average loss: 7.5442\n",
      "====> Epoch 95: Average loss: 7.5416\n",
      "====> Epoch 96: Average loss: 7.4940\n",
      "====> Epoch 97: Average loss: 7.6468\n",
      "====> Epoch 98: Average loss: 7.5202\n",
      "====> Epoch 99: Average loss: 7.4571\n",
      "====> Epoch 100: Average loss: 7.4698\n",
      "====> Epoch 101: Average loss: 7.5580\n",
      "====> Epoch 102: Average loss: 7.4191\n",
      "====> Epoch 103: Average loss: 7.4551\n",
      "====> Epoch 104: Average loss: 7.4752\n",
      "====> Epoch 105: Average loss: 7.4349\n",
      "====> Epoch 106: Average loss: 7.5048\n",
      "====> Epoch 107: Average loss: 7.3326\n",
      "====> Epoch 108: Average loss: 7.4284\n",
      "====> Epoch 109: Average loss: 7.4405\n",
      "====> Epoch 110: Average loss: 7.4567\n",
      "====> Epoch 111: Average loss: 7.4360\n",
      "====> Epoch 112: Average loss: 7.3723\n",
      "====> Epoch 113: Average loss: 7.3525\n",
      "====> Epoch 114: Average loss: 7.2916\n",
      "====> Epoch 115: Average loss: 7.2879\n",
      "====> Epoch 116: Average loss: 7.3821\n",
      "====> Epoch 117: Average loss: 7.2018\n",
      "====> Epoch 118: Average loss: 7.2706\n",
      "====> Epoch 119: Average loss: 7.3208\n",
      "====> Epoch 120: Average loss: 7.2812\n",
      "====> Epoch 121: Average loss: 7.3018\n",
      "====> Epoch 122: Average loss: 7.2070\n",
      "====> Epoch 123: Average loss: 7.2487\n",
      "====> Epoch 124: Average loss: 7.2672\n",
      "====> Epoch 125: Average loss: 7.2659\n",
      "====> Epoch 126: Average loss: 7.2801\n",
      "====> Epoch 127: Average loss: 7.2198\n",
      "====> Epoch 128: Average loss: 7.2626\n",
      "====> Epoch 129: Average loss: 7.1578\n",
      "====> Epoch 130: Average loss: 7.2378\n",
      "====> Epoch 131: Average loss: 7.0852\n",
      "====> Epoch 132: Average loss: 7.2468\n",
      "====> Epoch 133: Average loss: 7.1944\n",
      "====> Epoch 134: Average loss: 7.2181\n",
      "====> Epoch 135: Average loss: 7.1652\n",
      "====> Epoch 136: Average loss: 7.2486\n",
      "====> Epoch 137: Average loss: 7.1770\n",
      "====> Epoch 138: Average loss: 7.1068\n",
      "====> Epoch 139: Average loss: 7.2508\n",
      "====> Epoch 140: Average loss: 7.2104\n",
      "====> Epoch 141: Average loss: 7.1699\n",
      "====> Epoch 142: Average loss: 7.2597\n",
      "====> Epoch 143: Average loss: 7.1040\n",
      "====> Epoch 144: Average loss: 7.1938\n",
      "====> Epoch 145: Average loss: 7.1942\n",
      "====> Epoch 146: Average loss: 7.1813\n",
      "====> Epoch 147: Average loss: 7.1751\n",
      "====> Epoch 148: Average loss: 7.1124\n",
      "====> Epoch 149: Average loss: 7.2241\n",
      "====> Epoch 150: Average loss: 7.0517\n",
      "====> Epoch 151: Average loss: 7.0845\n",
      "====> Epoch 152: Average loss: 7.1072\n",
      "====> Epoch 153: Average loss: 7.0104\n",
      "====> Epoch 154: Average loss: 7.0995\n",
      "====> Epoch 155: Average loss: 7.1228\n",
      "====> Epoch 156: Average loss: 6.9803\n",
      "====> Epoch 157: Average loss: 7.0290\n",
      "====> Epoch 158: Average loss: 7.0971\n",
      "====> Epoch 159: Average loss: 7.0776\n",
      "====> Epoch 160: Average loss: 7.0632\n",
      "====> Epoch 161: Average loss: 7.0911\n",
      "====> Epoch 162: Average loss: 7.1455\n",
      "====> Epoch 163: Average loss: 7.0526\n",
      "====> Epoch 164: Average loss: 7.0117\n",
      "====> Epoch 165: Average loss: 7.1565\n",
      "====> Epoch 166: Average loss: 7.0425\n",
      "====> Epoch 167: Average loss: 7.0716\n",
      "====> Epoch 168: Average loss: 7.0312\n",
      "====> Epoch 169: Average loss: 7.0797\n",
      "====> Epoch 170: Average loss: 6.9680\n",
      "====> Epoch 171: Average loss: 7.0967\n",
      "====> Epoch 172: Average loss: 7.0694\n",
      "====> Epoch 173: Average loss: 7.0065\n",
      "====> Epoch 174: Average loss: 6.9253\n",
      "====> Epoch 175: Average loss: 6.9163\n",
      "====> Epoch 176: Average loss: 6.8830\n",
      "====> Epoch 177: Average loss: 7.0847\n",
      "====> Epoch 178: Average loss: 7.0727\n",
      "====> Epoch 179: Average loss: 6.8915\n",
      "====> Epoch 180: Average loss: 6.9656\n",
      "====> Epoch 181: Average loss: 7.0374\n",
      "====> Epoch 182: Average loss: 7.0161\n",
      "====> Epoch 183: Average loss: 6.9808\n",
      "====> Epoch 184: Average loss: 6.9837\n",
      "====> Epoch 185: Average loss: 6.9709\n",
      "====> Epoch 186: Average loss: 6.9972\n",
      "====> Epoch 187: Average loss: 6.9574\n",
      "====> Epoch 188: Average loss: 7.0102\n",
      "====> Epoch 189: Average loss: 6.9893\n",
      "====> Epoch 190: Average loss: 7.0273\n",
      "====> Epoch 191: Average loss: 6.9309\n",
      "====> Epoch 192: Average loss: 6.9477\n",
      "====> Epoch 193: Average loss: 6.9468\n",
      "====> Epoch 194: Average loss: 6.9957\n",
      "====> Epoch 195: Average loss: 6.9102\n",
      "====> Epoch 196: Average loss: 6.8561\n",
      "====> Epoch 197: Average loss: 7.0570\n",
      "====> Epoch 198: Average loss: 6.9377\n",
      "====> Epoch 199: Average loss: 6.8780\n",
      "====> Epoch 200: Average loss: 6.7840\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predict and get probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m_test = c_test*avai_test\n",
    "m_test = Variable(torch.Tensor(m_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recon_test, mu, logvar = model(m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([299, 280])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_test.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reshape predicted values\n",
    "recon_test = recon_test.view(c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([299, 35, 8]), (299, 35, 8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_test.size(), c_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "softmax = nn.Softmax()\n",
    "def getProbabilities(inp, inp_index, start_index):\n",
    "    softmax_input = softmax(input[inp_index, :, start_index:])\n",
    "    return softmax_input\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()\n",
    "for i in range(recon_test.size(0)):\n",
    "    cont_values = recon_test[i, :, 0].contiguous().view(recon_test.size(1),1) #(35,1)\n",
    "    softmax_values = softmax(recon_test[i, :, 1:])\n",
    "    if i == 0:\n",
    "        recon = torch.cat([cont_values, softmax_values], 1)\n",
    "        recon = recon.contiguous().view(1,recon_test.size(1), recon_test.size(2)) #(1, 35, 8)\n",
    "    else:\n",
    "        current_recon = torch.cat([cont_values, softmax_values], 1)\n",
    "        current_recon = current_recon.contiguous().view(1,recon_test.size(1), recon_test.size(2)) #(1, 35, 8)\n",
    "        recon = torch.cat([recon, current_recon], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([299, 35, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- predicted data: recon\n",
    "- complete data (normalized): c_test\n",
    "- nan matrix: nan_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5816926.9375617802"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalTime(recon, true_test, nan_test, min_array, max_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.71900826446280997, 1.5078322265436026)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalAct(recon, true_test, nan_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform Variable into numpy array\n",
    "recon = recon.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inversed_recon = inverse_minmaxScaler(recon, min_array, max_array, cols=[0])\n",
    "#inversed_c_test = inverse_minmaxScaler(c_test, min_array, max_array, cols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inversed_recon > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 35, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inversed_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10465"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "299*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_time = inversed_recon[:, :, 0]*nan_test[:, :, 0]\n",
    "predict_time = predict_time.reshape(c_test.shape[0]*c_test.shape[1], 1)\n",
    "predict_time = predict_time[~np.all(predict_time == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "true_time = true_test[:, :, 0]*nan_test[:, :, 0]\n",
    "true_time = true_time.reshape(c_test.shape[0]*c_test.shape[1], 1)\n",
    "true_time = true_time[~np.all(true_time == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366, 1), (366, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_time.shape, predict_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5816926.9375617802"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(true_time, predict_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.32554325881691"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5816926.9375617802/(24*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = inversed_recon[:, :, 1:]*nan_test[:, :, 1:]\n",
    "pred = pred.reshape(c_test.shape[0]*c_test.shape[1], c_test.shape[2]-1)\n",
    "missing_pred = pred[~np.all(pred == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gt = true_test[:, :, 1:]*nan_test[:, :, 1:]\n",
    "gt = gt.reshape(c_test.shape[0]*c_test.shape[1], c_test.shape[2]-1)\n",
    "missing_gt = gt[~np.all(gt == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363, 7), (363, 7))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_pred.shape, missing_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gt_label = missing_gt.argmax(axis=1)\n",
    "pred_label = missing_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71900826446280997"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gt_label, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5078322265436026"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(missing_gt, missing_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
